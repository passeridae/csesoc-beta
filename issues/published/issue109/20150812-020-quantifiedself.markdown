\endmulticols\LRmulticolcolumns

The Quantified Self
===================

\begin{center}
{\large\it It seems there are more reasons to learn machine learning
  than you'd think.}
\end{center}
\multicols{2}

One of the great blessings of modern information technology is our ability to collect lots of data and not do anything with it.  This has facilitated a new trend in the self-improvement world known as the quantified-shame`^W`self movement.  In theory, this involves collecting data about your health and habits and using it to determine how to take action in changing them for the better.  In practice, at least for me, it involves downloading as many apps as I can to track everything possible about me with my available hardware.

Starting the with basics: simplistic manual tools like _TickMate_ or _A Time Tracker_ (both fairly obscure open-source Android apps) that allow you to track Arbitrary Things!  Who wouldn't want to track whether, or for how long they walked the dog, or flossed their teeth, or chipped away at the latest zombie-vampire lord-of-the-flies-esque romantic comedy novel.  I found these apps were wonderful until I realised that I would often forget to fill them in (do you seriously expect me to press a button _every time_ I take a sip from a cup of water?), so naturally I moved on...

_TagTime_ is just like a time tracker but you never have to remind yourself to use it! Randomly, with an average of 45 minutes, my phone will make a distinct sequence of vibrations alerting me to the fact that I am due to be sampled!  That's right!  Random sampling!  So you don't anticipate when you're about to get caught out scrolling endlessly down your Facebook feed, and as the number of samples approaches infinity, your TagTime log becomes more of an accurate representation of you, so after a few months, you can, err, I'm not really sure, actually.

Let's move on to things I don't have to interact with!  _Google Fit_ somehow manages to work out for how much time you've been walking, running or cycling each day, despite how dodgy some of these accelerometers are (better than the GPS in my Nexus 4, anyway). I've been using this for a few weeks now, and it astounded me how many times I've managed to get to the default one hour goal, and it brought me to a sad realisation: I'm walking far too much!  I moved on campus to try and _minimise_ my commute, and I end up wasting all this time walking!  Clearly I need to move to the Barker Apartments so it isn't as far to K17, or better still, move my mattress into the old Socs office.

_RescueTime_ is even more depressing: It tracks everything you do on your personal computer.  However, I must admit, it does quite a good job of classifying the most obscure things, like my IRC client as a communication tool, and that _My Little Pony/1984_ fanfic I was reading as entertainment, although it unfortunately doesn't know when I'm using Facebook, so when I get my weekly email from _RescueTime_ telling me what a terrible person I am, 54% of my time is apparently a productivity-neutral category labelled 'Utilities'.  Heeeh... [^1]

After all this fatiguing data-collection, I began to ponder the point of all of this, until one day, I came across an interesting paper about a machine learning technique known as Random Forests™.  After reading a paragraph, I realised that this was exactly what I needed!  I exported every piece of data I could possibly find, aggregated it into days, categorised each of them with my subjective log of sleep quality that evening, pumped it all into a Random Forest™ to train it.  I spent days of tinkering with input data, trying to determine what I need to change about my lifestyle to feel like getting up in the morning, I noticed that no matter what I changed, the Random Forest™ would tell me that I would never achieve this.

"Oh wow!", I exclaimed.  "This is exactly the kind of disruptive technology the quantified-self market needs! Who could possibly have conceived that what people really need is a sophisticated recommendation engine that consistently told you that your goals were impossible!"  I quickly came up with a name that would resonate more with the market than 'Random Forests™' would: _Bayesian Winning-At-Life Recommendr_.  I swiftly registered the domain name `bayesianwinningatliferecommendr.institute` and hacked together a website filled with superfluous CSS transitions and purposeless Ajax queries, hoping to maximise the activity of the Internet's various hype machines and accrue offers from as many venture capital firms as the global economy could manage. I went to bed with _far_ too much adrenaline that evening.

Late at night, in the REM stage of my sleep cycle, I saw two ghostly figures wander into my room.  I recognised them immediately as the Professor/PhD student duo who published the original paper on Random Forests™.  "Take down your site, or we'll sue!" they demanded.  I refused, kindly reminding them that the only means they had to do so was their trademark, which I had already carefully scrubbed from my elevator pitch.  "We _do_ have more than one trademark, you know. We also trademarked the letters 'R' and 'F', when they occur in that order."  It was at this point that I realised that there was no way I could market _Bayesian Winning-At-Life Recommendr_ without using the substring "rf".  How could I possibly describe how it outpe\emph{rf}orms all the other purely supe\emph{rf}icial competition. How could I make the claim that this powe\emph{rf}ul recommendation engine is so pe\emph{rf}ect and wonde\emph{rf}ul?  I woke up in a cold sweat, leaping towards my laptop, logging into my server, typing `sudo killall python perl ruby nginx apache` having no time to remember which ones I used, selling the domain name off, deleting all my statistical models, uninstalling all quantified-self apps, overwriting all of my disks with random bytes... only to realise that by some supernatural hand, all of this had already been done for me.

\vspace*{1em}

So, uh, yeah.  Quantified-self is actually great when it's done properly; but that typically involves self-experimentation.  This may be an article for a time when I'm better at it.

[^1]: Some details after this point may be fabricated.

\byline{Daniel~Phillips}
